{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#import numba\n",
    "import tictactoe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 1]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 1]\n",
      " [2 2 0]\n",
      " [1 0 0]]\n",
      "Current state\n",
      "[[0 1 1]\n",
      " [2 2 0]\n",
      " [1 2 0]]\n",
      "Last state:\n",
      "[[1 1 1]\n",
      " [2 2 0]\n",
      " [1 2 0]]\n",
      "action_list=[2, 4, 6, 3, 1, 7, 0], reward=1.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 1 2]]\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [1 0 0]\n",
      " [0 1 2]]\n",
      "Current state\n",
      "[[2 0 2]\n",
      " [1 0 1]\n",
      " [0 1 2]]\n",
      "Current state\n",
      "[[2 1 2]\n",
      " [1 0 1]\n",
      " [2 1 2]]\n",
      "Last state:\n",
      "[[2 1 2]\n",
      " [1 1 1]\n",
      " [2 1 2]]\n",
      "action_list=[7, 8, 3, 2, 5, 0, 1, 6, 4], reward=1.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 2 1]]\n",
      "Current state\n",
      "[[2 1 0]\n",
      " [0 0 0]\n",
      " [0 2 1]]\n",
      "Current state\n",
      "[[2 1 0]\n",
      " [1 0 2]\n",
      " [0 2 1]]\n",
      "Current state\n",
      "[[2 1 0]\n",
      " [1 1 2]\n",
      " [2 2 1]]\n",
      "Last state:\n",
      "[[2 1 1]\n",
      " [1 1 2]\n",
      " [2 2 1]]\n",
      "action_list=[8, 7, 1, 0, 3, 5, 4, 6, 2], reward=0.5\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 2 0]\n",
      " [0 0 0]\n",
      " [0 1 0]]\n",
      "Current state\n",
      "[[0 2 2]\n",
      " [0 0 0]\n",
      " [0 1 1]]\n",
      "Current state\n",
      "[[1 2 2]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "Last state:\n",
      "[[1 2 2]\n",
      " [1 2 0]\n",
      " [2 1 1]]\n",
      "action_list=[7, 1, 8, 2, 0, 4, 3, 6], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[1 0 2]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[1 0 2]\n",
      " [0 1 0]\n",
      " [0 0 2]]\n",
      "Last state:\n",
      "[[1 1 2]\n",
      " [0 1 2]\n",
      " [0 0 2]]\n",
      "action_list=[0, 2, 4, 8, 1, 5], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[2 0 0]\n",
      " [0 0 0]\n",
      " [1 0 0]]\n",
      "Current state\n",
      "[[2 0 0]\n",
      " [2 0 1]\n",
      " [1 0 0]]\n",
      "Current state\n",
      "[[2 2 0]\n",
      " [2 0 1]\n",
      " [1 0 1]]\n",
      "Last state:\n",
      "[[2 2 2]\n",
      " [2 1 1]\n",
      " [1 0 1]]\n",
      "action_list=[6, 0, 5, 3, 8, 1, 4, 2], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 1 2]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 1 2]\n",
      " [0 0 0]\n",
      " [1 0 2]]\n",
      "Current state\n",
      "[[0 1 2]\n",
      " [0 2 1]\n",
      " [1 0 2]]\n",
      "Current state\n",
      "[[0 1 2]\n",
      " [2 2 1]\n",
      " [1 1 2]]\n",
      "Last state:\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 1 2]]\n",
      "action_list=[1, 2, 6, 8, 5, 4, 7, 3, 0], reward=0.5\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [2 0 1]]\n",
      "Current state\n",
      "[[0 2 0]\n",
      " [0 0 0]\n",
      " [2 1 1]]\n",
      "Current state\n",
      "[[1 2 2]\n",
      " [0 0 0]\n",
      " [2 1 1]]\n",
      "Current state\n",
      "[[1 2 2]\n",
      " [1 0 2]\n",
      " [2 1 1]]\n",
      "Last state:\n",
      "[[1 2 2]\n",
      " [1 1 2]\n",
      " [2 1 1]]\n",
      "action_list=[8, 6, 7, 1, 0, 2, 3, 5, 4], reward=1.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 2]]\n",
      "Current state\n",
      "[[0 2 0]\n",
      " [0 0 1]\n",
      " [1 0 2]]\n",
      "Current state\n",
      "[[2 2 0]\n",
      " [1 0 1]\n",
      " [1 0 2]]\n",
      "Last state:\n",
      "[[2 2 0]\n",
      " [1 1 1]\n",
      " [1 0 2]]\n",
      "action_list=[5, 8, 6, 1, 3, 0, 4], reward=1.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 2 1]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 1 0]\n",
      " [0 2 1]\n",
      " [2 0 0]]\n",
      "Current state\n",
      "[[0 1 0]\n",
      " [2 2 1]\n",
      " [2 0 1]]\n",
      "Current state\n",
      "[[1 1 0]\n",
      " [2 2 1]\n",
      " [2 2 1]]\n",
      "Last state:\n",
      "[[1 1 1]\n",
      " [2 2 1]\n",
      " [2 2 1]]\n",
      "action_list=[5, 4, 1, 6, 8, 3, 0, 7, 2], reward=1.0\n",
      "[1.  1.  0.5 0.  0.  0.  0.5 1.  1.  1. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10\n",
    "reward_a = np.zeros((N,))\n",
    "for i in range(N):\n",
    "    reward_a[i] = tictactoe.test_tictactoe_env(play_order=1)\n",
    "print(reward_a)\n",
    "np.average(reward_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state\n",
      "[[0 0 2]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [0 0 0]\n",
      " [0 1 2]]\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [2 1 0]\n",
      " [0 1 2]]\n",
      "Current state\n",
      "[[2 0 2]\n",
      " [2 1 1]\n",
      " [0 1 2]]\n",
      "Last state:\n",
      "[[2 1 2]\n",
      " [2 1 1]\n",
      " [0 1 2]]\n",
      "action_list=[2, 7, 8, 4, 3, 5, 0, 1], reward=1.0\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [0 0 2]\n",
      " [1 0 0]]\n",
      "Current state\n",
      "[[0 2 2]\n",
      " [0 1 2]\n",
      " [1 0 0]]\n",
      "Last state:\n",
      "[[1 2 2]\n",
      " [0 1 2]\n",
      " [1 0 2]]\n",
      "action_list=[2, 6, 5, 4, 1, 0, 8], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [2 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [2 0 0]\n",
      " [2 1 0]]\n",
      "Current state\n",
      "[[1 0 0]\n",
      " [2 0 0]\n",
      " [2 1 2]]\n",
      "Current state\n",
      "[[1 0 0]\n",
      " [2 1 2]\n",
      " [2 1 2]]\n",
      "Last state:\n",
      "[[1 2 1]\n",
      " [2 1 2]\n",
      " [2 1 2]]\n",
      "action_list=[6, 7, 3, 0, 8, 4, 5, 2, 1], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [2 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 1 0]\n",
      " [2 0 0]\n",
      " [0 0 2]]\n",
      "Current state\n",
      "[[0 1 0]\n",
      " [2 0 0]\n",
      " [1 2 2]]\n",
      "Current state\n",
      "[[0 1 2]\n",
      " [2 0 1]\n",
      " [1 2 2]]\n",
      "Last state:\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 2 2]]\n",
      "action_list=[3, 1, 8, 6, 7, 5, 2, 0, 4], reward=0.0\n",
      "Current state\n",
      "[[0 2 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[1 2 0]\n",
      " [0 0 0]\n",
      " [0 0 2]]\n",
      "Current state\n",
      "[[1 2 0]\n",
      " [0 0 0]\n",
      " [2 1 2]]\n",
      "Current state\n",
      "[[1 2 1]\n",
      " [0 2 0]\n",
      " [2 1 2]]\n",
      "Last state:\n",
      "[[1 2 1]\n",
      " [1 2 2]\n",
      " [2 1 2]]\n",
      "action_list=[1, 0, 8, 7, 6, 2, 4, 3, 5], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 1 0]\n",
      " [0 2 0]\n",
      " [2 0 0]]\n",
      "Current state\n",
      "[[0 1 0]\n",
      " [1 2 0]\n",
      " [2 0 2]]\n",
      "Current state\n",
      "[[0 1 0]\n",
      " [1 2 2]\n",
      " [2 1 2]]\n",
      "Last state:\n",
      "[[2 1 1]\n",
      " [1 2 2]\n",
      " [2 1 2]]\n",
      "action_list=[4, 1, 6, 3, 8, 7, 5, 2, 0], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 2 0]\n",
      " [0 2 1]]\n",
      "Current state\n",
      "[[2 0 0]\n",
      " [0 2 0]\n",
      " [1 2 1]]\n",
      "Current state\n",
      "[[2 0 1]\n",
      " [0 2 2]\n",
      " [1 2 1]]\n",
      "Last state:\n",
      "[[2 2 1]\n",
      " [1 2 2]\n",
      " [1 2 1]]\n",
      "action_list=[4, 8, 7, 6, 0, 2, 5, 3, 1], reward=0.0\n",
      "Current state\n",
      "[[0 2 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 2 2]\n",
      " [0 0 0]\n",
      " [0 1 0]]\n",
      "Last state:\n",
      "[[2 2 2]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "action_list=[1, 7, 2, 3, 0], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [2 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [2 1 0]\n",
      " [2 0 0]]\n",
      "Last state:\n",
      "[[2 1 0]\n",
      " [2 1 0]\n",
      " [2 0 0]]\n",
      "action_list=[6, 4, 3, 1, 0], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 2]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[2 0 0]\n",
      " [0 1 2]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[2 2 0]\n",
      " [0 1 2]\n",
      " [0 0 1]]\n",
      "Current state\n",
      "[[2 2 0]\n",
      " [2 1 2]\n",
      " [1 0 1]]\n",
      "Last state:\n",
      "[[2 2 0]\n",
      " [2 1 2]\n",
      " [1 1 1]]\n",
      "action_list=[5, 4, 0, 8, 1, 6, 3, 7], reward=1.0\n",
      "Current state\n",
      "[[2 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[2 2 0]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[2 2 0]\n",
      " [0 1 0]\n",
      " [0 1 2]]\n",
      "Current state\n",
      "[[2 2 0]\n",
      " [2 1 1]\n",
      " [0 1 2]]\n",
      "Last state:\n",
      "[[2 2 2]\n",
      " [2 1 1]\n",
      " [1 1 2]]\n",
      "action_list=[0, 4, 1, 7, 8, 5, 3, 6, 2], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 2 0]\n",
      " [1 2 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[2 2 0]\n",
      " [1 2 0]\n",
      " [0 0 1]]\n",
      "Last state:\n",
      "[[2 2 0]\n",
      " [1 2 0]\n",
      " [1 2 1]]\n",
      "action_list=[4, 3, 1, 8, 0, 6, 7], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 2 2]\n",
      " [0 1 0]]\n",
      "Last state:\n",
      "[[1 0 0]\n",
      " [2 2 2]\n",
      " [0 1 0]]\n",
      "action_list=[4, 7, 5, 0, 3], reward=0.0\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [0 0 0]\n",
      " [1 2 0]]\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [2 0 1]\n",
      " [1 2 0]]\n",
      "Current state\n",
      "[[0 0 2]\n",
      " [2 2 1]\n",
      " [1 2 1]]\n",
      "Last state:\n",
      "[[1 2 2]\n",
      " [2 2 1]\n",
      " [1 2 1]]\n",
      "action_list=[2, 6, 7, 5, 3, 8, 4, 0, 1], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 2 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [2 2 0]]\n",
      "Current state\n",
      "[[0 1 2]\n",
      " [1 0 0]\n",
      " [2 2 0]]\n",
      "Last state:\n",
      "[[1 1 2]\n",
      " [1 0 0]\n",
      " [2 2 2]]\n",
      "action_list=[7, 3, 6, 1, 2, 0, 8], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [2 0 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [1 2 0]\n",
      " [2 0 0]]\n",
      "Current state\n",
      "[[1 0 0]\n",
      " [1 2 2]\n",
      " [2 0 0]]\n",
      "Current state\n",
      "[[1 0 1]\n",
      " [1 2 2]\n",
      " [2 2 0]]\n",
      "Last state:\n",
      "[[1 2 1]\n",
      " [1 2 2]\n",
      " [2 2 1]]\n",
      "action_list=[6, 3, 4, 0, 5, 2, 7, 8, 1], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 2]]\n",
      "Current state\n",
      "[[2 0 0]\n",
      " [0 0 1]\n",
      " [0 0 2]]\n",
      "Last state:\n",
      "[[2 0 0]\n",
      " [0 2 1]\n",
      " [0 1 2]]\n",
      "action_list=[8, 5, 0, 7, 4], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 2 0]]\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [0 2 0]\n",
      " [0 2 1]]\n",
      "Current state\n",
      "[[0 0 1]\n",
      " [0 2 0]\n",
      " [2 2 1]]\n",
      "Current state\n",
      "[[1 0 1]\n",
      " [0 2 2]\n",
      " [2 2 1]]\n",
      "Last state:\n",
      "[[1 2 1]\n",
      " [1 2 2]\n",
      " [2 2 1]]\n",
      "action_list=[7, 8, 4, 2, 6, 0, 5, 3, 1], reward=0.0\n",
      "Current state\n",
      "[[0 0 0]\n",
      " [2 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[1 0 2]\n",
      " [2 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[1 2 2]\n",
      " [2 0 0]\n",
      " [0 1 0]]\n",
      "Current state\n",
      "[[1 2 2]\n",
      " [2 1 2]\n",
      " [0 1 0]]\n",
      "Last state:\n",
      "[[1 2 2]\n",
      " [2 1 2]\n",
      " [0 1 1]]\n",
      "action_list=[3, 0, 2, 7, 1, 4, 5, 8], reward=1.0\n",
      "Current state\n",
      "[[2 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Current state\n",
      "[[2 0 1]\n",
      " [0 0 0]\n",
      " [0 0 2]]\n",
      "Current state\n",
      "[[2 1 1]\n",
      " [2 0 0]\n",
      " [0 0 2]]\n",
      "Last state:\n",
      "[[2 1 1]\n",
      " [2 0 0]\n",
      " [2 1 2]]\n",
      "action_list=[0, 2, 8, 1, 3, 7, 6], reward=0.0\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 20\n",
    "reward_a = np.zeros((N,))\n",
    "for i in range(N):\n",
    "    reward_a[i] = tictactoe.test_tictactoe_env(play_order=2, disp_flag=True)\n",
    "print(reward_a)\n",
    "np.average(reward_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_a=[1.  1.  0.5 1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.  0.5 0.  1.  1.\n",
      " 1.  1.  1.  0.  1.  0.  0.  1.  0.  1.  0.  0.5 0.5 1.  0.  1.  0.  1.\n",
      " 0.  0.5 1.  0.  1.  1.  1.  0.  0.5 0.  0.  0.5 1.  0.  1.  1.  1.  0.\n",
      " 1.  1.  1.  1.  1.  0.5 0.5 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " 1.  0.  1.  0.5 1.  1.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " 1.  0.  1.  1.  0.5 1.  0.  0.  0.5 0.  1.  0.  1.  0.  1.  1.  1.  1.\n",
      " 0.5 1.  0.5 1.  1.  0.5 1.  1.  1.  0.5 0.  1.  0.  0.  1.  0.  0.  1.\n",
      " 0.  0.  0.  1.  1.  1.  0.5 1.  0.  1.  1.  1.  1.  1.  1.  0.5 1.  1.\n",
      " 1.  1.  0.  1.  1.  1.  0.  1.  0.  0.5 1.  1.  1.  1.  1.  0.  1.  1.\n",
      " 0.  1.  1.  0.5 1.  0.5 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.\n",
      " 1.  0.  1.  0.  0.5 1.  1.  1.  0.  0.5 0.5 0.  1.  1.  0.  1.  0.  1.\n",
      " 1.  1.  1.  1.  0.5 1.  1.  0.  1.  1.  0.  0.5 0.  0.5 0.  0.  0.  1.\n",
      " 1.  0.  0.5 0.  0.  1.  1.  1.  0.5 0.  1.  0.  0.5 0.  1.  1.  1.  1.\n",
      " 1.  1.  1.  1.  1.  1.  0.  0.5 1.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " 0.5 1.  1.  0.5 1.  1.  1.  1.  1.  0.  1.  0.  0.5 0.5 0.  1.  1.  0.\n",
      " 0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.\n",
      " 0.5 0.  0.  1.  0.  1.  1.  1.  0.  1.  0.  1.  0.5 1.  1.  1.  0.  1.\n",
      " 0.5 0.  0.  1.  1.  1.  1.  1.  0.5 1.  0.  1.  1.  1.  1.  1.  1.  1.\n",
      " 0.5 1.  1.  0.5 0.5 0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.\n",
      " 0.  1.  0.  1.  0.5 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.5 1.  1.  0.\n",
      " 1.  1.  0.5 1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  0.5 1.  1.  1.  1.\n",
      " 0.5 1.  0.  1.  1.  1.  0.5 0.5 0.5 1.  0.5 1.  0.5 1.  1.  1.  1.  1.\n",
      " 1.  0.  1.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.5 1.  0.  1.  1.  1.\n",
      " 1.  0.  1.  1.  0.  1.  0.  1.  0.  0.5 1.  0.  1.  1.  1.  1.  0.  1.\n",
      " 1.  1.  0.  0.  1.  0.  0.5 0.5 1.  0.  0.  1.  1.  0.  1.  0.  0.5 1.\n",
      " 0.5 0.  1.  0.5 0.  0.  1.  0.  0.  0.5 0.5 1.  0.  0.5 1.  1.  1.  0.5\n",
      " 1.  1.  0.  1.  0.5 0.  1.  0.  0.  1.  0.  0.  0.  0.5 1.  1.  1.  1.\n",
      " 1.  0.5 1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  0.  1.  0.  0.5 1.\n",
      " 0.  1.  1.  1.  1.  0.5 1.  1.  1.  1.  1.  0.  0.  0.5 0.  0.  0.5 0.5\n",
      " 1.  0.  1.  0.  0.5 1.  1.  1.  0.  1.  0.5 0.5 1.  0.  0.  1.  1.  1.\n",
      " 1.  0.  0.  1.  1.  0.5 0.5 1.  1.  0.  1.  1.  0.  1.  0.5 1.  0.5 0.5\n",
      " 0.  0.  1.  0.  1.  1.  1.  0.5 0.  1.  0.  1.  0.5 1.  0.  1.  0.  0.\n",
      " 0.5 1.  0.  1.  0.5 0.5 1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.  1.\n",
      " 0.  1.  1.  0.5 1.  0.  1.  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.  1.\n",
      " 1.  0.  0.  0.  1.  0.  1.  1.  0.5 1.  0.  1.  1.  1.  1.  1.  1.  1.\n",
      " 1.  1.  0.  1.  1.  1.  0.  0.  0.5 0.5 0.  1.  1.  0.  1.  1.  1.  0.5\n",
      " 1.  1.  1.  1.  1.  0.5 1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  0.5 1.\n",
      " 0.  1.  0.5 0.  1.  1.  0.  0.5 0.5 0.  1.  0.  1.  0.  0.  1.  1.  0.\n",
      " 1.  0.5 1.  1.  0.5 1.  0.  1.  1.  1.  1.  0.5 1.  0.5 1.  1.  0.5 1.\n",
      " 1.  1.  0.  0.  1.  1.  0.5 0.  0.5 1.  0.5 1.  0.  0.5 1.  0.  1.  0.\n",
      " 1.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.5 0.  1.  1.\n",
      " 0.  1.  0.  1.  1.  1.  0.5 0.  0.  1.  0.  1.  1.  0.5 0.  0.  0.5 1.\n",
      " 1.  0.  1.  1.  1.  0.  1.  1.  0.5 0.  0.5 1.  1.  1.  1.  0.  1.  0.5\n",
      " 1.  0.  1.  0.5 1.  1.  1.  0.  0.  0.5 0.  1.  1.  1.  0.  0.  1.  1.\n",
      " 0.5 0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.5 1.  1.  1.\n",
      " 0.  0.5 0.  1.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.  0.  1.  1.  0.\n",
      " 1.  0.  1.  1.  1.  0.  1.  0.  0.  1.  1.  0.5 1.  1.  0.  0.5 0.5 1.\n",
      " 0.5 0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.5 1.  1.  1.\n",
      " 1.  1.  0.  1.  1.  1.  0.  1.  1.  0.5 0.  0.5 0.5 1.  0.5 0.  1.  1.\n",
      " 1.  1.  0.  0.5 1.  1.  0.5 1.  0.5 1.  0.  0.  1.  0.  1.  0.5 0.  0.5\n",
      " 1.  1.  1.  1.  1.  1.  1.  1.  0.5 0.5 1.  1.  1.  1.  0.  1.  1.  0.\n",
      " 1.  0.  1.  1.  0.  1.  0.5 1.  0.  0.  0.  1.  1.  1.  1.  0.  0.5 0.5\n",
      " 1.  1.  0.  1.  1.  1.  0.  0.  1.  0.5 1.  0.  0.  1.  0.  0.5 1.  1.\n",
      " 0.  1.  1.  1.  0.5 0.5 0.5 1.  1.  0.5 0.  1.  0.  1.  1.  0.  1.  1.\n",
      " 1.  1.  1.  1.  0.5 0.5 0.5 1.  1.  0.5 1.  1.  1.  1.  1.  0.5 0.5 0.5\n",
      " 0.  0.  1.  1.  0.  1.  0.  1.  1.  0. ]\n",
      "average reward=0.6535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6535"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tictactoe.multiple_test_tictactoe_env(1000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_a=[1.  0.  0.  0.  0.  0.  0.  0.5 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.5 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.5 0.5 1.  0.  0.5 0.  0.  1.  1.  0.  1.  0.5 1.  1.\n",
      " 0.  1.  0.  1.  0.  0.  0.  0.5 0.  0.  1.  0.  0.  1.  1.  0.  1.  0.\n",
      " 0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.5\n",
      " 0.  0.5 0.  1.  0.  0.  0.  0.  0.5 1.  0.  0.  0.  0.  1.  0.  0.  1.\n",
      " 0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.5 0.5 1.  0.  0.  0.  0.  0.\n",
      " 1.  0.  0.5 0.5 0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.\n",
      " 0.  1.  0.  0.  1.  0.5 0.  1.  0.  1.  0.  0.  0.5 0.  1.  1.  0.  0.\n",
      " 0.  0.5 0.  0.  1.  0.5 0.5 0.5 0.  0.  0.5 0.  0.  1.  0.  0.  0.5 1.\n",
      " 0.  0.  0.5 0.  0.  0.  0.5 1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.\n",
      " 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.\n",
      " 0.  0.  0.  1.  0.5 0.  0.5 1.  0.5 0.  0.5 0.  0.  0.5 0.  1.  0.  1.\n",
      " 0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.5 0.5 0.5 0.  0.5 0.  0.5\n",
      " 0.  0.  1.  0.  1.  0.5 1.  0.  1.  1.  1.  1.  0.5 0.5 1.  0.  0.  0.\n",
      " 0.  1.  1.  0.  0.5 0.  0.5 1.  1.  1.  0.  0.5 1.  1.  0.  1.  0.  0.5\n",
      " 0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  1.  0.5 0.  0.5 0.  0.\n",
      " 0.5 0.  1.  0.  0.5 0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.\n",
      " 0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  1.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.  0.5 0.5 0.  0.5 0.  1.  1.\n",
      " 0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.5 0.5 0.  0.  0.\n",
      " 0.5 1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.\n",
      " 1.  1.  0.  1.  0.5 1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.5\n",
      " 0.5 0.  0.  0.  0.  1.  0.  0.5 0.  0.  0.  1.  0.  0.5 1.  1.  1.  0.\n",
      " 0.5 1.  1.  0.  0.5 0.5 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.\n",
      " 0.  0.  0.  0.  0.  1.  0.  1.  0.5 0.  0.5 1.  0.  0.  0.5 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.5 0.  1.  0.  0.  0.5 0.  0.  1.  0.  0.5 0.5\n",
      " 0.  1.  0.  0.  1.  0.  0.5 0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.\n",
      " 1.  0.  1.  0.  0.  0.  0.5 0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.\n",
      " 1.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.  1.  1.  0.  0.  0.  1.  0.  0.\n",
      " 0.  1.  1.  1.  0.5 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 1.  1.  0.  0.  1.  0.  0.  0.  1.  0.5 0.  0.  0.5 0.  0.  0.5 0.  0.\n",
      " 0.5 0.  0.  0.  0.  1.  1.  0.  0.  0.  0.5 1.  0.5 0.  1.  1.  0.  1.\n",
      " 0.5 1.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  1.  1.  0.  0.  0.  0.5 0.\n",
      " 0.  1.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.5 1.  0.  0.  0.  1.  0.\n",
      " 1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.\n",
      " 1.  0.  1.  0.  0.  0.  1.  1.  0.5 1.  1.  1.  1.  0.  1.  1.  1.  1.\n",
      " 0.  0.5 0.  0.5 0.5 0.  0.  0.  0.  0.  0.5 1.  0.  0.  0.  0.  0.  0.\n",
      " 0.5 0.5 0.5 0.  1.  0.  0.  0.  1.  0.  0.  0.5 0.  0.5 0.  0.  0.  0.\n",
      " 0.  1.  0.  1.  0.5 1.  0.5 0.  0.  0.5 1.  0.  0.  0.5 0.  0.5 0.  1.\n",
      " 0.  0.  0.  0.  0.  0.  1.  1.  0.5 0.  0.  1.  0.  0.  0.  0.  0.  0.5\n",
      " 0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.5 0.5 1.\n",
      " 0.5 0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.5 0.  0.  0.\n",
      " 1.  1.  0.  0.  1.  0.5 0.  0.  0.  0.5 0.  1.  1.  0.  0.  0.  0.  0.\n",
      " 1.  1.  0.  1.  0.5 1.  1.  0.  0.  0.5 0.5 1.  0.5 1.  0.  1.  0.5 0.\n",
      " 1.  0.  1.  0.5 1.  0.  0.  0.  0.  0.5 0.5 0.  0.  0.  0.  0.  0.5 0.5\n",
      " 1.  0.  1.  1.  0.5 0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.\n",
      " 1.  1.  0.5 1.  0.  1.  0.5 0.  0.  0.5 0.  0.  1.  0.  0.  1.  0.  0.\n",
      " 0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.\n",
      " 0.  1.  0.  0.5 1.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.5\n",
      " 0.  0.5 0.  0.  1.  0.  0.5 1.  0.  0.  0.  0.  0.  0.  0.  1.  0.5 1.\n",
      " 0.  0.  0.5 0.  0.  0.  0.5 1.  1.  1.  0.5 1.  0.  0.  0.  0.5 0.  1.\n",
      " 1.  0.  1.  0.  1.  0.5 0.  0.  0.  1.  0.  0.5 0.  0.5 0.  0.  0.  0.\n",
      " 0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.\n",
      " 0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.\n",
      " 1.  0.5 0.  0.  1.  0.5 0.  1.  0.  0. ]\n",
      "average reward=0.359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.359"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tictactoe.multiple_test_tictactoe_env(1000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0125"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.359 + 0.6535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 2],\n",
       "       [2, 1, 1],\n",
       "       [1, 2, 1]], dtype=int16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list = [1, 0, 8, 7, 6, 2, 4, 3, 5]\n",
    "S = tictactoe.action_list_2_state(action_list)\n",
    "S.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tictactoe.calc_reward_numba(tictactoe.MASK_L, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
