{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [array([0.5, 0.5]), array([0.5, 0.5]), array([0.5, 0.5]), array([0.5, 0.5])]\n",
      "v[0]=-2.5057415905523253\n",
      "v[1]=-1.6060272426565467\n",
      "v[2]=2.4316473139847745\n",
      "v[3]=7.135350237940245\n",
      "v[4]=0.0\n",
      "q[0][0]=-3.3266059231766705\n",
      "q[0][1]=-1.6848772579279794\n",
      "q[1][0]=-3.3516633390821924\n",
      "q[1][1]=0.13960885376910126\n",
      "q[2][0]=0.0\n",
      "q[2][1]=4.863294627969549\n",
      "q[3][0]=4.270700475880492\n",
      "q[3][1]=10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class MDP:\n",
    "    def __init__(self):\n",
    "        self.init_policy_Rsa()\n",
    "        \n",
    "    def init_policy_Rsa(self):\n",
    "        # policy[state][action] = 0.9 (<-- prob)\n",
    "        # None state is the last state        \n",
    "        self.policy_actions_table = [['Facebook', 'Quit'], ['Facebook', 'Study'], \n",
    "            ['Sleep', 'Study'], ['Pub', 'Study'], None]\n",
    "        self.Rsa = [[-1,0], [-1,-2], [0, -2], [1,10]]\n",
    "        self.N_states = len(self.policy_actions_table)\n",
    "        self.policy = []\n",
    "        for actions in self.policy_actions_table:\n",
    "            if actions:\n",
    "                N_actions = len(actions)\n",
    "                self.policy.append(np.ones(N_actions)/N_actions)\n",
    "                \n",
    "        # policy가 고려되지 않은 관계임. Policy에 따른 가중에 별도로 고려되어야 함.\n",
    "        self.Psas = np.zeros([self.N_states, 2, self.N_states]) # Probability\n",
    "        self.Psas[0,0,0], self.Psas[0,1,1] = 1.0, 1.0\n",
    "        self.Psas[1,0,0], self.Psas[1,1,2] = 1.0, 1.0\n",
    "        self.Psas[2,0,4], self.Psas[2,1,3] = 1.0, 1.0\n",
    "        self.Psas[3,0,1], self.Psas[3,0,2], \\\n",
    "            self.Psas[3,0,3], self.Psas[3,1,4] = 0.2, 0.4, 0.4, 1.0 \n",
    "        \n",
    "    def init_v(self):\n",
    "        self.v = np.zeros(self.N_states)\n",
    "        \n",
    "    def init_q(self):\n",
    "        self.q = []\n",
    "        for s in range(self.N_states - 1):\n",
    "            self.q.append(np.zeros(len(self.policy[s])))\n",
    "        self.q.append(0)\n",
    "        \n",
    "    def calc_bellman_v(self, s:int) -> float:\n",
    "        return bellman_v(self.v, self.policy, self.Rsa, self.Psas, s=s)    \n",
    "    \n",
    "    def calc_bellman_q(self, s:int, a:int) -> float:\n",
    "        #return 0\n",
    "        return bellman_q(self.q, self.policy, self.Rsa, self.Psas, s=s, a=a)    \n",
    "    \n",
    "    def get_v(self, N_iter:int=10) -> np.ndarray:\n",
    "        self.init_v()\n",
    "        for n in range(N_iter):\n",
    "            for s in range(self.N_states-1):\n",
    "                self.v[s] = (self.v[s] * n + self.calc_bellman_v(s))/(n+1)        \n",
    "        \n",
    "        for s in range(self.N_states):\n",
    "            print(f'v[{s}]={self.v[s]}')\n",
    "        return self.v\n",
    "    \n",
    "    def get_q(self, N_iter:int=10) -> List:\n",
    "        self.init_q()\n",
    "        \n",
    "        for n in range(N_iter):\n",
    "            for s in range(self.N_states-1):\n",
    "                for a in range(len(self.policy[s])):\n",
    "                    #print(f'[?]s,a={s,a} --> {self.q[s][a]}')\n",
    "                    self.q[s][a] = (self.q[s][a] * n + \n",
    "                        self.calc_bellman_q(s,a))/(n+1)  \n",
    "                    #self.q[s][a] = (self.q[s][a] * n)/(n+1) \n",
    "        \n",
    "        for s in range(self.N_states-1):\n",
    "            for a in range(len(self.policy[s])):\n",
    "                print(f'q[{s}][{a}]={self.q[s][a]}')\n",
    "        return self.q      \n",
    "    \n",
    "    def test(self, N_Iter:int=100):\n",
    "        print(f'Policy: {self.policy}')\n",
    "        self.get_v(N_Iter)\n",
    "        self.get_q(N_Iter)\n",
    "\n",
    "        \n",
    "def bellman_v(v:np.ndarray, policy:List, Rsa:List, Psas:np.ndarray, \n",
    "        s:int=0, forgetting_factor:float=1.0) -> float:\n",
    "    Gs = 0\n",
    "    for a in range(len(policy[s])):\n",
    "        Gs += policy[s][a] * bellman_q_by_v(v, Rsa, Psas, \n",
    "                s=s, a=a, forgetting_factor=forgetting_factor)\n",
    "    return Gs\n",
    "\n",
    "def bellman_q_by_v(v:np.ndarray, Rsa:List, Psas:np.ndarray, \n",
    "        s:int=0, a:int=0, forgetting_factor:float=1.0) -> float:\n",
    "    reward = Rsa[s][a]\n",
    "    v_next = 0\n",
    "    for next_s in range(len(Psas[s,a])):\n",
    "        if Psas[s,a,next_s] and next_s < len(v) - 1:\n",
    "            v_next += Psas[s,a,next_s] * v[next_s]     \n",
    "    Gs = reward + forgetting_factor * v_next\n",
    "    return Gs\n",
    "\n",
    "def bellman_q(q:List, policy:List, Rsa:List, Psas:np.ndarray, \n",
    "        s:int=0, a:int=0, forgetting_factor:float=1.0) -> float:\n",
    "    reward = Rsa[s][a]\n",
    "    v_next = 0\n",
    "    for next_s in range(len(Psas[s,a])):\n",
    "        if Psas[s,a,next_s] and next_s < len(q) - 1:\n",
    "            v = 0\n",
    "            for next_a in range(len(policy[next_s])):\n",
    "                v += policy[next_s][next_a] * q[next_s][next_a]\n",
    "            v_next += Psas[s,a,next_s] * v     \n",
    "    Gs = reward + forgetting_factor * v_next\n",
    "    return Gs\n",
    "             \n",
    "MDP().test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
